{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irYwurUDqqPf",
        "outputId": "23c561ba-3e1b-4753-c74e-414131829f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m144.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision torchaudio numpy pandas spacy datasets sacrebleu matplotlib tqdm\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.1 torchtext==0.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0iuCPNisCZg",
        "outputId": "881f4c50-89f7-438e-9db3-ca98ab062efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.1\n",
            "  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1133762760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch==2.3.1 torchtext==0.18.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mmake_file\u001b[0;34m(name, hash, size_str)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackagePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhash\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # Thiết lập dữ liệu [cite: 4, 5]\n",
        "        self.src_lang = 'vi'\n",
        "        self.tgt_lang = 'en'\n",
        "        self.max_len = 100         # Độ dài tối đa của câu (để cắt/pad)\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Thiết lập Mô hình (Model Architecture) [cite: 10]\n",
        "        self.d_model = 512        # Kích thước vector embedding\n",
        "        self.n_heads = 8          # Số lượng Head trong Multi-Head Attention\n",
        "        self.n_layers = 6         # Số lớp Encoder và Decoder\n",
        "        self.d_ff = 2048          # Kích thước lớp ẩn trong Feed Forward Network\n",
        "        self.dropout = 0.1\n",
        "\n",
        "        # Thiết lập Huấn luyện (Training) [cite: 27, 29]\n",
        "        self.lr = 0.0001          # Learning rate\n",
        "        self.epochs = 20\n",
        "        self.warmup_steps = 4000  # Cho Scheduler\n",
        "        self.label_smoothing = 0.1 # Kỹ thuật giúp model đỡ overfit\n",
        "\n",
        "        # Đường dẫn lưu model\n",
        "        self.model_path = 'weights/transformer_vi_en.pth'\n",
        "\n",
        "cfg = Config()"
      ],
      "metadata": {
        "id": "UQYu4vq7qyX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import sacrebleu\n",
        "import math\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "# Thiết lập các token đặc biệt (Rất quan trọng!)\n",
        "PAD_TOKEN = '<pad>' # Dùng để đệm câu cho bằng độ dài\n",
        "SOS_TOKEN = '<sos>' # Start of Sentence - Báo hiệu bắt đầu câu\n",
        "EOS_TOKEN = '<eos>' # End of Sentence - Báo hiệu kết thúc câu\n",
        "UNK_TOKEN = '<unk>' # Unknown - Dùng cho các từ không có trong từ điển\n",
        "\n",
        "PAD_IDX = 0\n",
        "SOS_IDX = 1\n",
        "EOS_IDX = 2\n",
        "UNK_IDX = 3"
      ],
      "metadata": {
        "id": "MzkKq-fuq_rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=2):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer_en(text):\n",
        "        # Sử dụng tokenizer chuẩn cho tiếng Anh\n",
        "        tokenizer = get_tokenizer('basic_english')\n",
        "        return tokenizer(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer_vi(text):\n",
        "        # CẢI TIẾN: Hàm tách từ tiếng Việt\n",
        "        # Nếu cài được thư viện 'pyvi' hoặc 'underthesea' thì thay vào đây\n",
        "        # Tạm thời dùng split() nhưng xử lý kỹ hơn về dấu câu\n",
        "        text = text.lower().strip()\n",
        "        # Tách dấu câu đơn giản (để dấu chấm, phẩy không dính vào từ)\n",
        "        for char in ['.', ',', '?', '!', '\"', \"'\"]:\n",
        "            text = text.replace(char, f\" {char} \")\n",
        "        return text.split()\n",
        "\n",
        "    def build_vocabulary(self, sentence_list, lang='en'):\n",
        "        frequencies = Counter()\n",
        "        idx = 4\n",
        "\n",
        "        tokenizer_fn = self.tokenizer_en if lang == 'en' else self.tokenizer_vi\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "            for word in tokenizer_fn(sentence):\n",
        "                frequencies[word] += 1\n",
        "\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def numericalize(self, text, lang='en'):\n",
        "        tokenizer_fn = self.tokenizer_en if lang == 'en' else self.tokenizer_vi\n",
        "        tokenized_text = tokenizer_fn(text)\n",
        "\n",
        "        return [\n",
        "            self.stoi[token] if token in self.stoi else self.stoi[\"<unk>\"]\n",
        "            for token in tokenized_text\n",
        "        ]\n",
        "\n",
        "    # Thêm chức năng lưu/tải từ điển để không phải build lại\n",
        "    def save_vocab(self, path):\n",
        "        with open(path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.stoi, f, ensure_ascii=False)\n",
        "\n",
        "    def load_vocab(self, path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            self.stoi = json.load(f)\n",
        "            self.itos = {v: k for k, v in self.stoi.items()}"
      ],
      "metadata": {
        "id": "4icZErITHoEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_text = self.src_sentences[index]\n",
        "        tgt_text = self.tgt_sentences[index]\n",
        "\n",
        "        # Map từ -> số\n",
        "        src_indices = [self.src_vocab.stoi[\"<sos>\"]] + \\\n",
        "                      self.src_vocab.numericalize(src_text, lang='vi') + \\\n",
        "                      [self.src_vocab.stoi[\"<eos>\"]]\n",
        "\n",
        "        tgt_indices = [self.tgt_vocab.stoi[\"<sos>\"]] + \\\n",
        "                      self.tgt_vocab.numericalize(tgt_text, lang='en') + \\\n",
        "                      [self.tgt_vocab.stoi[\"<eos>\"]]\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)"
      ],
      "metadata": {
        "id": "3iI9jbbUIfUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        src_batch, tgt_batch = [], []\n",
        "        for src_item, tgt_item in batch:\n",
        "            src_batch.append(src_item)\n",
        "            tgt_batch.append(tgt_item)\n",
        "\n",
        "        # Padding\n",
        "        src_batch = pad_sequence(src_batch, padding_value=self.pad_idx, batch_first=True)\n",
        "        tgt_batch = pad_sequence(tgt_batch, padding_value=self.pad_idx, batch_first=True)\n",
        "\n",
        "        return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "pAe4ilwGIiAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        # Lớp Embedding chuẩn của PyTorch\n",
        "        self.emb = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Theo paper gốc \"Attention Is All You Need\", ta nhân embedding với căn bậc 2 của d_model\n",
        "        # Lý do: Để giá trị của embedding có độ lớn tương đương với Positional Encoding sắp cộng vào\n",
        "        return self.emb(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "nzKn4oA0qydP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model: Kích thước vector embedding (thường là 512)\n",
        "            max_len: Độ dài tối đa của câu mà mô hình hỗ trợ\n",
        "            dropout: Xác suất dropout để tránh overfitting\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Tạo ma trận PE kích thước (max_len, d_model) chứa toàn số 0\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Tạo vector vị trí (pos): [0, 1, 2, ..., max_len-1]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Tính div_term (mẫu số trong công thức): 10000^(2i/d_model)\n",
        "        # Sử dụng log space để tính toán ổn định hơn về mặt số học\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Áp dụng công thức Sin cho vị trí chẵn (2i)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Áp dụng công thức Cos cho vị trí lẻ (2i+1)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Thêm 1 chiều batch ở đầu: (1, max_len, d_model) để dễ cộng với input\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer giúp lưu trữ tensor này vào state_dict của mô hình\n",
        "        # nhưng không cập nhật nó trong quá trình backpropagation (vì nó cố định)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor kích thước (batch_size, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        # Cắt ma trận PE cho khớp với độ dài câu hiện tại (seq_len)\n",
        "        # x.size(1) chính là độ dài câu thực tế\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "HyRY3ZjQvBZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model: Kích thước vector embedding (ví dụ: 512)\n",
        "            n_heads: Số lượng 'đầu' chú ý (ví dụ: 8)\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0, \"d_model phải chia hết cho n_heads\"\n",
        "\n",
        "        self.d_head = d_model // n_heads\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # 1. Các lớp Linear để tạo ra Q, K, V từ đầu vào\n",
        "        # W_q, W_k, W_v trong lý thuyết\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Lớp Linear cuối cùng sau khi nối các heads lại\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            query: (Batch, Seq_len, D_model)\n",
        "            key:   (Batch, Seq_len, D_model)\n",
        "            value: (Batch, Seq_len, D_model)\n",
        "            mask:  Tensor chứa giá trị 0 hoặc 1 để che đi các vị trí không cần thiết\n",
        "        \"\"\"\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # 1. Tính toán Q, K, V\n",
        "        Q = self.w_q(query) # (Batch, Seq_len, D_model)\n",
        "        K = self.w_k(key)   # (Batch, Seq_len, D_model)\n",
        "        V = self.w_v(value) # (Batch, Seq_len, D_model)\n",
        "\n",
        "        # 2. Chia nhỏ thành n_heads\n",
        "        # Biến đổi: (Batch, Seq_len, D_model) -> (Batch, Seq_len, n_heads, d_head)\n",
        "        # Sau đó đảo trục để n_heads lên trước: (Batch, n_heads, Seq_len, d_head)\n",
        "        # Việc này giúp tính toán song song các heads\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "\n",
        "        # 3. Scaled Dot-Product Attention\n",
        "        # Tính điểm năng lượng: (Batch, n_heads, Seq_len_Q, Seq_len_K)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
        "\n",
        "        # 4. Áp dụng Mask (Nếu có)\n",
        "        # Mask thường dùng để:\n",
        "        # - Che padding (Padding Mask)\n",
        "        # - Che các từ tương lai trong Decoder (Look-ahead Mask)\n",
        "        if mask is not None:\n",
        "            # Những chỗ mask == 0 sẽ bị gán giá trị âm vô cùng (-1e9)\n",
        "            # Để khi qua Softmax nó sẽ bằng 0\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # 5. Softmax để ra xác suất chú ý\n",
        "        attention_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # 6. Nhân với V\n",
        "        out = torch.matmul(attention_weights, V) # (Batch, n_heads, Seq_len_Q, d_head)\n",
        "\n",
        "        # 7. Ghép lại (Concatenate)\n",
        "        # Đảo trục lại: (Batch, Seq_len_Q, n_heads, d_head)\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "\n",
        "        # Gom lại thành vector d_model ban đầu: (Batch, Seq_len_Q, D_model)\n",
        "        out = out.view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # 8. Lớp Linear cuối cùng\n",
        "        out = self.fc_out(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "NhX4_SbhvBcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Mạng Feed-Forward (FFN) được áp dụng cho từng vị trí riêng biệt và giống hệt nhau.\n",
        "    Công thức: FFN(x) = max(0, xW1 + b1)W2 + b2\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        # Mở rộng kích thước từ d_model lên d_ff (thường gấp 4 lần, ví dụ 512 -> 2048)\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> Linear -> ReLU -> Dropout -> Linear\n",
        "        return self.w_2(self.dropout(self.relu(self.w_1(x))))"
      ],
      "metadata": {
        "id": "oKE9u9KxvBeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Một lớp Encoder bao gồm 2 phần chính:\n",
        "    1. Multi-Head Self-Attention\n",
        "    2. Position-wise Feed-Forward Network\n",
        "    Mỗi phần đều có Residual Connection (Add) và Layer Normalization (Norm).\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        # [cite_start]Thành phần 1: Self-Attention [cite: 17]\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model) # [cite: 18]\n",
        "\n",
        "        # [cite_start]Thành phần 2: Feed Forward [cite: 19]\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # 1. Sub-layer 1: Self-Attention\n",
        "        # Residual connection: x + Sublayer(x)\n",
        "        _src = self.self_attn(src, src, src, src_mask)\n",
        "        src = self.norm1(src + self.dropout(_src))\n",
        "\n",
        "        # 2. Sub-layer 2: Feed Forward\n",
        "        _src = self.ffn(src)\n",
        "        src = self.norm2(src + self.dropout(_src))\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "-JrA33iOqygA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Một lớp Decoder phức tạp hơn, bao gồm 3 phần:\n",
        "    1. Masked Multi-Head Self-Attention (để không nhìn thấy tương lai)\n",
        "    2. Multi-Head Cross-Attention (nhìn vào Encoder output)\n",
        "    3. Position-wise Feed-Forward Network\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # [cite_start]1. Masked Self-Attention [cite: 21]\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # [cite_start]2. Cross-Attention (Encoder-Decoder Attention) [cite: 22]\n",
        "        # Query lấy từ Decoder, Key & Value lấy từ Encoder\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # [cite_start]3. Feed Forward [cite: 23]\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, enc_out, tgt_mask, src_mask):\n",
        "        # Sub-layer 1: Masked Self-Attention (chú ý vào chính câu đích)\n",
        "        _tgt = self.self_attn(tgt, tgt, tgt, tgt_mask)\n",
        "        tgt = self.norm1(tgt + self.dropout(_tgt))\n",
        "\n",
        "        # Sub-layer 2: Cross-Attention (chú ý vào câu nguồn - Encoder Output)\n",
        "        # query=tgt, key=enc_out, value=enc_out\n",
        "        _tgt = self.enc_dec_attn(tgt, enc_out, enc_out, src_mask)\n",
        "        tgt = self.norm2(tgt + self.dropout(_tgt))\n",
        "\n",
        "        # Sub-layer 3: Feed Forward\n",
        "        _tgt = self.ffn(tgt)\n",
        "        tgt = self.norm3(tgt + self.dropout(_tgt))\n",
        "\n",
        "        return tgt"
      ],
      "metadata": {
        "id": "6QmaPhSWwnoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, n_layers, n_heads, d_ff, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        # Tạo danh sách N lớp EncoderLayer\n",
        "        # ModuleList giúp PyTorch quản lý các layer này\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, src, mask):\n",
        "        # src đi qua từng lớp EncoderLayer lần lượt\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, mask)\n",
        "        return self.norm(src)"
      ],
      "metadata": {
        "id": "CeOIgdEKwnqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, n_layers, n_heads, d_ff, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        # Tạo danh sách N lớp DecoderLayer\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask, src_mask):\n",
        "        \"\"\"\n",
        "        tgt: Input của Decoder (câu đang dịch)\n",
        "        memory: Output của Encoder (thông tin từ câu nguồn)\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory, tgt_mask, src_mask)\n",
        "        return self.norm(tgt)"
      ],
      "metadata": {
        "id": "M5_dYWy-xdDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        d_model=512,\n",
        "        n_layers=6,\n",
        "        n_heads=8,\n",
        "        d_ff=2048,\n",
        "        dropout=0.1,\n",
        "        max_len=5000,\n",
        "        src_pad_idx=0,\n",
        "        tgt_pad_idx=0\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.tgt_pad_idx = tgt_pad_idx\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # 1. Khởi tạo phần Embedding + Positional Encoding\n",
        "        self.src_embedding = TokenEmbedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = TokenEmbedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_len, dropout)\n",
        "\n",
        "        # 2. Khởi tạo khối Encoder và Decoder\n",
        "        self.encoder = Encoder(d_model, n_layers, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(d_model, n_layers, n_heads, d_ff, dropout)\n",
        "\n",
        "        # 3. Lớp đầu ra (Generator): Chiếu về kích thước từ điển đích\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        # Khởi tạo tham số (Xavier init) giúp hội tụ nhanh hơn\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        # Tạo mask cho Encoder: Che các vị trí padding\n",
        "        # src shape: (batch_size, src_len)\n",
        "        # mask shape: (batch_size, 1, 1, src_len)\n",
        "        mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def make_tgt_mask(self, tgt):\n",
        "        # Tạo mask cho Decoder: Gồm 2 phần\n",
        "        # 1. Padding mask: Che các vị trí padding\n",
        "        # 2. Look-ahead mask: Che các từ tương lai (dạng tam giác trên)\n",
        "\n",
        "        # Padding mask\n",
        "        padding_mask = (tgt != self.tgt_pad_idx).unsqueeze(1).unsqueeze(3)\n",
        "\n",
        "        # Look-ahead mask (tam giác)\n",
        "        tgt_len = tgt.shape[1]\n",
        "        look_ahead_mask = torch.tril(torch.ones(tgt_len, tgt_len)).type(torch.ByteTensor).to(self.device)\n",
        "\n",
        "        # Kết hợp cả 2: Vừa phải không phải padding, vừa phải nằm trong quá khứ\n",
        "        mask = padding_mask & look_ahead_mask\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # 1. Tạo Mask\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        tgt_mask = self.make_tgt_mask(tgt)\n",
        "\n",
        "        # 2. Forward qua Encoder\n",
        "        # Input: (Batch, Src_Len) -> Output: (Batch, Src_Len, D_Model)\n",
        "        src_emb = self.positional_encoding(self.src_embedding(src))\n",
        "        enc_src = self.encoder(src_emb, src_mask)\n",
        "\n",
        "        # 3. Forward qua Decoder\n",
        "        # Input: (Batch, Tgt_Len) -> Output: (Batch, Tgt_Len, D_Model)\n",
        "        tgt_emb = self.positional_encoding(self.tgt_embedding(tgt))\n",
        "        output = self.decoder(tgt_emb, enc_src, tgt_mask, src_mask)\n",
        "\n",
        "        # 4. Chiếu ra xác suất từ\n",
        "        return self.fc_out(output)"
      ],
      "metadata": {
        "id": "Yopy2YfmxdF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, iterator, optimizer, criterion, clip, device):\n",
        "    \"\"\"\n",
        "    Hàm huấn luyện cho 1 Epoch (duyệt qua toàn bộ dữ liệu 1 lần)\n",
        "    \"\"\"\n",
        "    model.train() # Chuyển sang chế độ training (bật Dropout)\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, tgt) in enumerate(iterator):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        # Decoder Input: Bỏ token cuối cùng <eos>\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        # Target Output: Bỏ token đầu tiên <sos> (đây là cái ta muốn model đoán)\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        optimizer.zero_grad() # Xóa gradient cũ\n",
        "\n",
        "        # Forward pass\n",
        "        # output shape: (batch_size, tgt_len - 1, output_dim)\n",
        "        output = model(src, tgt_input)\n",
        "\n",
        "        # Reshape để tính Loss\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        tgt_output = tgt_output.contiguous().view(-1)\n",
        "\n",
        "        # Tính Loss (Cross Entropy)\n",
        "        loss = criterion(output, tgt_output)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Cắt gradient (Gradient Clipping) để tránh bùng nổ gradient\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # Cập nhật trọng số\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "QsXmw_tcxdIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \"\"\"\n",
        "    Hàm đánh giá trên tập Validation (không cập nhật trọng số)\n",
        "    \"\"\"\n",
        "    model.eval() # Chuyển sang chế độ eval (tắt Dropout)\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad(): # Không tính gradient giúp chạy nhanh hơn\n",
        "        for i, (src, tgt) in enumerate(iterator):\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            tgt_output = tgt_output.contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_output)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "oRz-Miu6x9sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_plot(train_losses, val_losses, title, filename):\n",
        "    \"\"\"\n",
        "    Vẽ và lưu biểu đồ Loss theo Epoch\n",
        "    Args:\n",
        "        train_losses: List chứa giá trị loss của tập train qua từng epoch\n",
        "        val_losses: List chứa giá trị loss của tập val qua từng epoch\n",
        "        title: Tiêu đề biểu đồ\n",
        "        filename: Tên file ảnh muốn lưu (ví dụ: 'loss_chart.png')\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Train Loss', color='blue', marker='o')\n",
        "    plt.plot(val_losses, label='Validation Loss', color='red', marker='x')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Lưu ảnh\n",
        "    if not os.path.exists('reports'):\n",
        "        os.makedirs('reports')\n",
        "    plt.savefig(os.path.join('reports', filename))\n",
        "    plt.close()\n",
        "    print(f\"--> Đã lưu biểu đồ tại: reports/{filename}\")\n",
        "\n",
        "def save_perplexity_plot(train_losses, val_losses, filename):\n",
        "    \"\"\"\n",
        "    Vẽ biểu đồ Perplexity (PPL = exp(Loss))\n",
        "    PPL càng thấp càng tốt.\n",
        "    \"\"\"\n",
        "    train_ppls = [math.exp(l) for l in train_losses]\n",
        "    val_ppls = [math.exp(l) for l in val_losses]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_ppls, label='Train PPL', color='green', linestyle='--')\n",
        "    plt.plot(val_ppls, label='Val PPL', color='orange', linestyle='--')\n",
        "\n",
        "    plt.title(\"Model Perplexity over Epochs\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.yscale('log') # Dùng thang log vì PPL có thể rất lớn lúc đầu\n",
        "    plt.grid(True)\n",
        "\n",
        "    if not os.path.exists('reports'):\n",
        "        os.makedirs('reports')\n",
        "    plt.savefig(os.path.join('reports', filename))\n",
        "    plt.close()\n",
        "    print(f\"--> Đã lưu biểu đồ PPL tại: reports/{filename}\")"
      ],
      "metadata": {
        "id": "02hPagyiPsvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "Ou0ZFrhxSUDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training():\n",
        "    # 1. Cấu hình (Hyperparameters) - Nên để trong config file riêng, nhưng để đây cho tiện\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    BATCH_SIZE = 32\n",
        "    N_EPOCHS = 10\n",
        "    CLIP = 1\n",
        "    LR = 0.0001\n",
        "\n",
        "    # # 2. Chuẩn bị Dữ liệu (Giả lập hoặc Load thật)\n",
        "    # print(\"--- Đang chuẩn bị dữ liệu ---\")\n",
        "    # # LƯU Ý: Ở đây cậu thay bằng code load file IWSLT thật\n",
        "    # # Demo dữ liệu giả để code chạy được ngay\n",
        "    # train_src = [\"tôi là sinh viên\", \"máy học rất thú vị\"] * 50\n",
        "    # train_tgt = [\"i am a student\", \"machine learning is interesting\"] * 50\n",
        "    # val_src = [\"tôi đi học\", \"xin chào\"] * 10\n",
        "    # val_tgt = [\"i go to school\", \"hello\"] * 10\n",
        "\n",
        "    print(\"--- Đang tải dataset IWSLT2015 (Vi-En) ---\")\n",
        "    dataset = load_dataset(\"nguyenvuhuy/iwslt2015-en-vi\")\n",
        "\n",
        "    def extract_data(data_split):\n",
        "        src = [item['vi'] for item in data_split]\n",
        "        tgt = [item['en'] for item in data_split]\n",
        "        return src, tgt\n",
        "\n",
        "    train_src, train_tgt = extract_data(dataset['train'])\n",
        "    val_src, val_tgt = extract_data(dataset['validation'])\n",
        "\n",
        "    # Tokenizer & Vocab\n",
        "    # Removed: from utils.tokenizer import Vocabulary\n",
        "    vocab_src = Vocabulary(freq_threshold=1)\n",
        "    vocab_tgt = Vocabulary(freq_threshold=1)\n",
        "    # Build vocab từ dữ liệu train\n",
        "    vocab_src.build_vocabulary(train_src, lang='vi')\n",
        "    vocab_tgt.build_vocabulary(train_tgt, lang='en')\n",
        "\n",
        "    print(f\"Vocab Source: {len(vocab_src)} | Vocab Target: {len(vocab_tgt)}\")\n",
        "\n",
        "    # DataLoader\n",
        "    train_dataset = BilingualDataset(train_src, train_tgt, vocab_src, vocab_tgt)\n",
        "    val_dataset = BilingualDataset(val_src, val_tgt, vocab_src, vocab_tgt)\n",
        "\n",
        "    collate = Collate(pad_idx=0) # 0 là <pad>\n",
        "\n",
        "    train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
        "    valid_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
        "\n",
        "    # 3. Khởi tạo Mô hình\n",
        "    model = Transformer(\n",
        "        src_vocab_size=len(vocab_src),\n",
        "        tgt_vocab_size=len(vocab_tgt),\n",
        "        d_model=256,    # Demo dùng nhỏ, bài thật dùng 512\n",
        "        n_layers=3,     # Demo dùng 3, bài thật dùng 6\n",
        "        n_heads=8,\n",
        "        d_ff=512,\n",
        "        dropout=0.1,\n",
        "        src_pad_idx=vocab_src.stoi[\"<pad>\"],\n",
        "        tgt_pad_idx=vocab_tgt.stoi[\"<pad>\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # 4. Optimizer & Loss\n",
        "    # Adam Optimizer [cite: 29]\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    # Cross Entropy Loss [cite: 28]\n",
        "    # Quan trọng: ignore_index=0 để không tính loss cho các token <pad>\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab_tgt.stoi[\"<pad>\"])\n",
        "\n",
        "    # 5. Vòng lặp Training [cite: 30]\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    train_loss_history = []\n",
        "    valid_loss_history = []\n",
        "\n",
        "    print(\"--- Bắt đầu Training ---\")\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_epoch(model, train_iterator, optimizer, criterion, CLIP, device)\n",
        "        valid_loss = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "        train_loss_history.append(train_loss)\n",
        "        valid_loss_history.append(valid_loss)\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        # Lưu model tốt nhất\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'transformer_model.pt')\n",
        "            print(f\"--> Đã lưu model tốt nhất tại Epoch {epoch+1}\")\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "\n",
        "    print(\"\\n--- Đang vẽ biểu đồ báo cáo ---\")\n",
        "\n",
        "    # 1. Vẽ biểu đồ Loss\n",
        "    save_training_plot(\n",
        "        train_loss_history,\n",
        "        valid_loss_history,\n",
        "        title=f'Training Loss (Epochs={N_EPOCHS})',\n",
        "        filename='loss_chart.png'\n",
        "    )\n",
        "\n",
        "    # 2. Vẽ biểu đồ Perplexity\n",
        "    save_perplexity_plot(\n",
        "        train_loss_history,\n",
        "        valid_loss_history,\n",
        "        filename='perplexity_chart.png'\n",
        "    )"
      ],
      "metadata": {
        "id": "WxqjRxq7yBBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_vocab, tgt_vocab, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Xử lý câu nguồn (Source)\n",
        "    # Tokenize và thêm <sos>, <eos>\n",
        "    # tokens = [src_vocab.stoi[\"<sos>\"]] + src_vocab.numericalize(sentence) + [src_vocab.stoi[\"<eos>\"]]#đã fix dòng này\n",
        "    tokens = [src_vocab.stoi[\"<sos>\"]] + src_vocab.numericalize(sentence, lang='vi') + [src_vocab.stoi[\"<eos>\"]]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device) # (1, src_len)\n",
        "\n",
        "    # Tạo mask cho src\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode câu nguồn\n",
        "        src_emb = model.positional_encoding(model.src_embedding(src_tensor))\n",
        "        enc_src = model.encoder(src_emb, src_mask)\n",
        "\n",
        "    # 2. Khởi tạo câu đích với <sos>\n",
        "    tgt_indices = [tgt_vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    # 3. Vòng lặp Decoding\n",
        "    for i in range(max_len):\n",
        "        tgt_tensor = torch.LongTensor(tgt_indices).unsqueeze(0).to(device) # (1, curr_len)\n",
        "\n",
        "        # Tạo mask cho tgt\n",
        "        tgt_mask = model.make_tgt_mask(tgt_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Decode\n",
        "            tgt_emb = model.positional_encoding(model.tgt_embedding(tgt_tensor))\n",
        "            output = model.decoder(tgt_emb, enc_src, tgt_mask, src_mask)\n",
        "\n",
        "            # Lấy dự đoán cho từ cuối cùng\n",
        "            pred_token_logits = model.fc_out(output[:, -1, :])\n",
        "\n",
        "            # Chọn từ có xác suất cao nhất (Greedy)\n",
        "            pred_token = pred_token_logits.argmax(1).item()\n",
        "\n",
        "            # Nếu gặp <eos> thì dừng\n",
        "            if pred_token == tgt_vocab.stoi[\"<eos>\"]:\n",
        "                break\n",
        "\n",
        "            tgt_indices.append(pred_token)\n",
        "\n",
        "    # 4. Chuyển từ số về chữ\n",
        "    trg_tokens = [tgt_vocab.itos[i] for i in tgt_indices]\n",
        "\n",
        "    # Bỏ <sos> ở đầu\n",
        "    return trg_tokens[1:]"
      ],
      "metadata": {
        "id": "rOx4pJ9CyBD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tính BLEU Score\n",
        "def calculate_bleu(data, src_vocab, tgt_vocab, model, device):\n",
        "\n",
        "\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = example[0] # Câu tiếng Việt gốc\n",
        "        trg = example[1] # Câu tiếng Anh gốc\n",
        "\n",
        "        prediction = translate_sentence(src, src_vocab, tgt_vocab, model, device)\n",
        "\n",
        "        # Nối lại thành câu\n",
        "        pred_sent = \" \".join(prediction)\n",
        "\n",
        "        outputs.append(pred_sent)\n",
        "        targets.append([trg]) # Sacrebleu yêu cầu list of lists cho reference\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(outputs, targets)\n",
        "    return bleu.score"
      ],
      "metadata": {
        "id": "MeIeIiNvx9u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "k-X3rFhFx9xZ",
        "outputId": "3b1edbc8-3382-4870-cc8b-dd064de55ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Đang tải dataset IWSLT2015 (Vi-En) ---\n",
            "Vocab Source: 21144 | Vocab Target: 47271\n",
            "--- Bắt đầu Training ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.27 GiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1127541654.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3861332673.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3705448275.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, iterator, optimizer, criterion, clip, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Cắt gradient (Gradient Clipping) để tránh bùng nổ gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.27 GiB. GPU "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint_and_predict():\n",
        "    # 1. Cấu hình thiết bị\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Đang sử dụng thiết bị: {device}\")\n",
        "\n",
        "    # 2. Tái tạo Vocabulary (BẮT BUỘC PHẢI KHỚP VỚI LÚC TRAIN)\n",
        "    # Lưu ý: Trong dự án thực tế, bạn nên lưu vocab ra file json và load lại.\n",
        "    # Ở đây mình build lại nhanh từ dữ liệu mẫu để demo.\n",
        "    print(\"--- Đang load Vocabulary ---\")\n",
        "    train_src = [\"tôi là sinh viên\", \"máy học rất thú vị\"] * 50\n",
        "    train_tgt = [\"i am a student\", \"machine learning is interesting\"] * 50\n",
        "\n",
        "    # Instantiate tokenizers first\n",
        "    src_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "    tgt_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "    vocab_src = Vocabulary()\n",
        "    vocab_tgt = Vocabulary()\n",
        "    vocab_src.build_vocabulary(train_src, lang='vi')\n",
        "    vocab_tgt.build_vocabulary(train_tgt, lang='en')\n",
        "\n",
        "    # 3. Khởi tạo lại kiến trúc mô hình (Cấu hình phải khớp với lúc train)\n",
        "    print(\"--- Đang khởi tạo mô hình ---\")\n",
        "    model = Transformer(\n",
        "        src_vocab_size=len(vocab_src),\n",
        "        tgt_vocab_size=len(vocab_tgt),\n",
        "        d_model=256,      # Khớp với train.py\n",
        "        n_layers=3,       # Khớp với train.py\n",
        "        n_heads=8,\n",
        "        d_ff=512,\n",
        "        dropout=0.1,\n",
        "        src_pad_idx=vocab_src.stoi[\"<pad>\"],\n",
        "        tgt_pad_idx=vocab_tgt.stoi[\"<pad>\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # 4. Load trọng số đã train (File .pt)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('transformer_model.pt', map_location=device))\n",
        "        print(\"--> Đã load trọng số từ 'transformer_model.pt' thành công!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"LỖI: Không tìm thấy file 'transformer_model.pt'. Bạn đã chạy train.py chưa?\")\n",
        "        return\n",
        "\n",
        "    # 5. Dịch thử\n",
        "    sentences = [\n",
        "        \"tôi là sinh viên\",\n",
        "        \"máy học rất thú vị\",\n",
        "        \"tôi là sinh viên máy học\" # Câu ghép thử thách hơn chút\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ DỊCH ---\")\n",
        "    for sentence in sentences:\n",
        "        result = translate_sentence(\n",
        "            sentence,\n",
        "            vocab_src,\n",
        "            vocab_tgt,\n",
        "            model,\n",
        "            device,\n",
        "            max_len=20\n",
        "        )\n",
        "\n",
        "        print(f\"Tiếng Việt: {sentence}\")\n",
        "        print(f\"Tiếng Anh : {' '.join(result)}\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "tWDVMIgKx92I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint_and_predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF66axE1x94g",
        "outputId": "70c743b5-d8a2-4cb9-c7e0-1082f97c957d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang sử dụng thiết bị: cuda\n",
            "--- Đang load Vocabulary ---\n",
            "--- Đang khởi tạo mô hình ---\n",
            "--> Đã load trọng số từ 'transformer_model.pt' thành công!\n",
            "\n",
            "--- KẾT QUẢ DỊCH ---\n",
            "Tiếng Việt: tôi là sinh viên\n",
            "Tiếng Anh : i am am am am am\n",
            "------------------------------\n",
            "Tiếng Việt: máy học rất thú vị\n",
            "Tiếng Anh : \n",
            "------------------------------\n",
            "Tiếng Việt: tôi là sinh viên máy học\n",
            "Tiếng Anh : i\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL9MdmwOx96o",
        "outputId": "97ab64d1-6db2-42c4-a8f8-54be848a5f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_bleu_score(model, dataset, src_vocab, tgt_vocab, device):\n",
        "    \"\"\"\n",
        "    Hàm tính điểm BLEU trên toàn bộ tập dữ liệu\n",
        "    Args:\n",
        "        dataset: List các tuple (câu nguồn, câu đích)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    hypotheses = [] # Danh sách các câu máy dịch (Prediction)\n",
        "    references = [] # Danh sách các câu đáp án (Ground Truth)\n",
        "\n",
        "    print(f\"Đang tiến hành dịch và đánh giá {len(dataset)} câu...\")\n",
        "\n",
        "    # Dùng tqdm để hiển thị thanh tiến trình vì bước này có thể lâu\n",
        "    for src_text, tgt_text in tqdm(dataset):\n",
        "        # 1. Máy dịch\n",
        "        pred_tokens = translate_sentence(\n",
        "            src_text,\n",
        "            src_vocab,\n",
        "            tgt_vocab,\n",
        "            model,\n",
        "            device,\n",
        "            max_len=50\n",
        "        )\n",
        "\n",
        "        # Nối các token lại thành câu hoàn chỉnh\n",
        "        # Lưu ý: Cần join cẩn thận để tách đúng từ.\n",
        "        # Ở đây ta join bằng space đơn giản cho demo.\n",
        "        pred_str = \" \".join(pred_tokens)\n",
        "\n",
        "        # 2. Lưu lại kết quả\n",
        "        hypotheses.append(pred_str)\n",
        "        references.append(tgt_text)\n",
        "\n",
        "    # 3. Tính điểm BLEU dùng thư viện sacrebleu\n",
        "    # sacrebleu yêu cầu references phải là list of lists (vì 1 câu nguồn có thể có nhiều cách dịch)\n",
        "    # Nhưng ở đây ta chỉ có 1 đáp án cho mỗi câu nên ta bọc nó lại: [references]\n",
        "    bleu = sacrebleu.corpus_bleu(hypotheses, [references])\n",
        "\n",
        "    return bleu.score"
      ],
      "metadata": {
        "id": "3M7HczFAqyiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # 1. Cấu hình\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n",
        "    # 2. Tái tạo Vocabulary (PHẢI GIỐNG LÚC TRAIN)\n",
        "    # Mẹo: Trong thực tế, bạn nên load vocab từ file json đã lưu.\n",
        "    # Ở đây mình giả lập lại quy trình build vocab y hệt file train.py\n",
        "    train_src = [\"tôi là sinh viên\", \"máy học rất thú vị\"] * 50\n",
        "    train_tgt = [\"i am a student\", \"machine learning is interesting\"] * 50\n",
        "\n",
        "    # vocab_src = Vocabulary(tokenizer=src_tokenizer, min_freq=1)\n",
        "    # vocab_tgt = Vocabulary(tokenizer=src_tokenizer, min_freq=1)\n",
        "    # vocab_src.build_vocabulary(train_src,)\n",
        "    # vocab_tgt.build_vocabulary(train_tgt,)\n",
        "\n",
        "    vocab_src = Vocabulary()\n",
        "    vocab_tgt = Vocabulary()\n",
        "    vocab_src.build_vocabulary(train_src, lang='vi')\n",
        "    vocab_tgt.build_vocabulary(train_tgt, lang='en')\n",
        "\n",
        "    # 3. Load Model Architecture\n",
        "    model = Transformer(\n",
        "        src_vocab_size=len(vocab_src),\n",
        "        tgt_vocab_size=len(vocab_tgt),\n",
        "        d_model=256,    # Phải khớp config lúc train\n",
        "        n_layers=3,     # Phải khớp config lúc train\n",
        "        n_heads=8,\n",
        "        d_ff=512,\n",
        "        dropout=0.1,\n",
        "        src_pad_idx=vocab_src.stoi[\"<pad>\"],\n",
        "        tgt_pad_idx=vocab_tgt.stoi[\"<pad>\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # 4. Load Model Weights\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('transformer_model.pt', map_location=device))\n",
        "        print(\"Đã load trọng số mô hình thành công!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Lỗi: Không tìm thấy file 'transformer_model.pt'. Vui lòng chạy train.py trước.\")\n",
        "\n",
        "    # 5. Chuẩn bị tập Test (Dữ liệu chưa từng gặp khi train)\n",
        "    # Bạn thay thế phần này bằng dữ liệu IWSLT test thật\n",
        "    test_data = [\n",
        "        (\"tôi là sinh viên\", \"i am a student\"),\n",
        "        (\"máy học rất thú vị\", \"machine learning is interesting\"),\n",
        "        (\"tôi đi học\", \"i go to school\"), # Câu mới\n",
        "    ]\n",
        "\n",
        "    # 6. Tính toán\n",
        "    score = calculate_bleu(test_data,vocab_src,vocab_tgt,model,device)\n",
        "    # score = calculate_bleu_score(model, test_data, vocab_src, vocab_tgt, device)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\"KẾT QUẢ CUỐI CÙNG\")\n",
        "    print(f\"BLEU Score: {score:.2f}\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # Đánh giá sơ bộ\n",
        "    if score > 30:\n",
        "        print(\"Đánh giá: Mô hình RẤT TỐT (Chất lượng dịch máy thương mại)\")\n",
        "    elif score > 20:\n",
        "        print(\"Đánh giá: Mô hình TỐT (Hiểu được ngữ nghĩa, sai ngữ pháp nhẹ)\")\n",
        "    elif score > 10:\n",
        "        print(\"Đánh giá: TRUNG BÌNH (Dịch được từ khóa, cấu trúc câu còn lộn xộn)\")\n",
        "    else:\n",
        "        print(\"Đánh giá: KÉM (Cần train nhiều hơn hoặc kiểm tra lại dữ liệu)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrpdEDueE9xE",
        "outputId": "9c00a207-bbfe-40da-a146-89d035d23a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda\n",
            "Đã load trọng số mô hình thành công!\n",
            "\n",
            "==============================\n",
            "KẾT QUẢ CUỐI CÙNG\n",
            "BLEU Score: 16.23\n",
            "==============================\n",
            "Đánh giá: TRUNG BÌNH (Dịch được từ khóa, cấu trúc câu còn lộn xộn)\n"
          ]
        }
      ]
    }
  ]
}